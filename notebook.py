# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kAft748mVHN21gc9QPVD2Ynl3BaGmKx4

# Proyek Akhir: Menyelesaikan Permasalahan Institusi Pendidikan

- Nama: Faris Ghina Purohita
- Email: farisghina51@gmail.com

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

# Import library
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score
from sklearn.model_selection import GridSearchCV
import joblib

pip install pandas sqlalchemy

import pandas as pd
df = pd.read_csv("https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/refs/heads/main/students_performance/data.csv",delimiter=';')

"""### Menyiapkan data yang akan diguankan

## Data Understanding
"""

df.head()

df.info()

"""Dataset terdiri dari 4424 baris dan 37 kolom, dengan 29 kolom bertipe int64, 7 kolom float64, dan 1 kolom object."""

df.describe(include='all')

"""Variabel kategorikal seperti course, application_mode, dan nationality memiliki rentang nilai yang luas, namun berdasarkan dokumentasi, nilai-nilai tersebut merepresentasikan kategori sah dan bukan outlier

## Data Preparation / Preprocessing
"""

print("Jumlah duplikasi: ", df.duplicated().sum())

"""pada fungsi `df.info()` diatas sudah terlihat bahwa data tidak memiliki missing value, yaitu terlihat bahwa data berjumlah 4424 semua. Dan juga tidak terdapat data duplikat

**Univariate Analysis**
"""

# Identifikasi kolom numerical
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Univariate analysis untuk numerical variables
plt.figure(figsize=(18, 20))
for i, col in enumerate(numerical_columns, 1):
    plt.subplot(len(numerical_columns) // 3 + 1, 3, i)
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

"""Tidak terdapat pola yang cukup menarik, ini karena sebagian besar merupakan kolom kategorikal yang direpresentasikan dalam bentuk numerik."""

# Identifikasi kolom categorical
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()

# Univariate analysis untuk categorical variables
plt.figure(figsize=(20, 5))
for i, col in enumerate(categorical_columns, 1):
    plt.subplot(len(categorical_columns) // 3 + 1, 3, i)
    ax = sns.countplot(data=df, x=col)
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=90)
    for p in ax.patches:
        height = p.get_height()
        ax.text(p.get_x() + p.get_width() / 2, height + 1, int(height), ha='center', va='bottom')
plt.tight_layout()
plt.show()

"""Kolom `status` memiliki tiga kategori yaitu dropout, graduate, dan enrolled. Kategori graduate memiliki jumlah paling banyak yaitu lebih dari 2209, dropout 1421, dan enrolled 794

**Multivariate Analysis**

Multivariate analysis relatif terhadap kolom target yaitu kolom Status, dengan memilih kolom kategorikal yang direpresentasikan oleh numerik kemudian mengubah nilai numerik menjadi nilai aslinya agar memudahkan proses analysis tanpa mengubah datasetnya
"""

# Salin dataframe
df_multivariate = df.copy()

# Dictionary pemetaan beberapa nilai numerik ke label deskriptif
replacement_mappings = {
    'Gender': {1: 'Male', 0: 'Female'},
    'Scholarship_holder': {1: 'Yes', 0: 'No'},
    'International': {1: 'Yes', 0: 'No'},
    'Marital_status': {
        1: 'Single', 2: 'Married', 3: 'Widower', 4: 'Divorced', 5: 'Facto Union', 6: 'Legally Separated'
    },
    'Course': {
        33: 'Biofuel Production Technologies', 171: 'Animation and Multimedia Design',
        8014: 'Social Service (evening)', 9003: 'Agronomy', 9070: 'Communication Design',
        9085: 'Veterinary Nursing', 9119: 'Informatics Engineering', 9130: 'Equinculture',
        9147: 'Management', 9238: 'Social Service', 9254: 'Tourism', 9500: 'Nursing',
        9556: 'Oral Hygiene', 9670: 'Advertising & Marketing', 9773: 'Journalism & Communication',
        9853: 'Basic Education', 9991: 'Management (evening)'
    },
    'Nacionality': {
        1: 'Portuguese', 2: 'German', 6: 'Spanish', 11: 'Italian', 13: 'Dutch', 14: 'English',
        17: 'Lithuanian', 21: 'Angolan', 22: 'Cape Verdean', 24: 'Guinean', 25: 'Mozambican',
        26: 'Santomean', 32: 'Turkish', 41: 'Brazilian', 62: 'Romanian', 100: 'Moldova',
        101: 'Mexican', 103: 'Ukrainian', 105: 'Russian', 108: 'Cuban', 109: 'Colombian'
    },
}

# Terapkan mapping dan ubah tipe ke category
for col, mapping in replacement_mappings.items():
    df_multivariate[col] = df_multivariate[col].replace(mapping).astype('category')

# Mapping Status
df_multivariate['Status'] = df_multivariate['Status'].replace({0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'})

# Ambil semua kolom kategorikal
categorical_features = df_multivariate.select_dtypes(include='category').columns.tolist()

# Plot semua fitur kategorikal terhadap Status
for col in categorical_features:
    g = sns.catplot(
        data=df_multivariate,
        x=col,
        hue='Status',
        kind='count',
        palette='pastel',
        height=4, aspect=3
    )

    # Judul & label
    g.fig.suptitle(f"Distribusi Status terhadap {col}", fontsize=16, y=1.05)
    g.set_xlabels(col, fontsize=12)
    g.set_ylabels("Jumlah", fontsize=12)

    # Posisikan legend di kanan atas
    g._legend.set_title("Status")
    g._legend.set_bbox_to_anchor((1, 1.02))
    g._legend.set_frame_on(False)

    # Rotasi label sumbu X
    plt.xticks(rotation=90)

    # Tambahkan angka di atas setiap batang
    for ax in g.axes.flat:
        for p in ax.patches:
            height = p.get_height()
            if height > 0:
                ax.text(
                    x=p.get_x() + p.get_width() / 2,
                    y=height + 0.5,
                    s=f'{int(height)}',
                    ha='center', va='bottom',
                    fontsize=9
                )

    # Tambahkan padding antar plot
    plt.subplots_adjust(top=0.9, bottom=0.25)

    plt.show()

"""Mahasiswa dengan status 'Single' mendominasi dataset, dan mahasiswa 'Married' memiliki proporsi dropout yang cukup tinggi.
Terdapat variasi yang signifikan dalam distribusi status mahasiswa antar program studi, menunjukkan bahwa program studi
mungkin memiliki pengaruh terhadap status mahasiswa. Mahasiswa penerima beasiswa cenderung memiliki tingkat dropout
yang lebih rendah dan lebih banyak yang graduate dibandingkan dengan mahasiswa yang tidak menerima beasiswa.
"""

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# One-hot encoding untuk fitur kategorikal
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Membuat matriks korelasi untuk seluruh fitur (numerik dan kategorikal yang telah dienkode)
correlation_matrix = df_encoded.corr()

# Plot matriks korelasi
plt.figure(figsize=(40, 25))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix of All Variables (Including Encoded Categorical Features)')
plt.show()

"""Variabel akademik, memiliki korelasi positif terkuat dengan status mahasiswa, sementara variabel demografis dan sosial ekonomi memiliki korelasi yang sangat lemah atau mendekati 0 dengan status mahasiswa. Lebih banyak kolom yang berkorelasi negatif dengan kolom target (status) dibandingkan dengan yang berkorelasi positif."""

# Mengubah kolom target 'Status' menjadi numerik
status_mapping = {'Dropout': 0,'Enrolled':1,'Graduate': 2}
df_mapping = df.copy()
df_mapping['Status'] = df['Status'].replace(status_mapping)

# One-hot encoding untuk fitur kategorikal (kecuali kolom target 'Status')
df_encoded = pd.get_dummies(df_mapping, columns=[col for col in categorical_columns if col != 'Status'], drop_first=True)

# Membuat matriks korelasi untuk seluruh fitur (numerik dan kategorikal yang telah dienkode)
correlation_matrix = df_encoded.corr()

# Ambil korelasi dengan kolom 'Attrition'
attrition_correlation = correlation_matrix["Status"].sort_values(ascending=False)

factors = attrition_correlation
factors = factors.drop('Status')

# Plot the top 10 correlations
plt.figure(figsize=(10, 8))
sns.barplot(x=factors.values, y=factors.index, hue=factors.index, palette="coolwarm")
plt.title("Features Most Correlated with Attrition")
plt.xlabel("Correlation with Status")
plt.ylabel("Factor")
for i, (count) in enumerate(factors.values):
    plt.text(count, i, str(count), va='center')
plt.tight_layout()
plt.show()

"""`curricular_units_2nd_sem_approved` merupakan kolom yang memiliki nilai korelasi paling tinggi dengan kolom status, dan kolom dengan korelasi terkecil yaitu kolom `Age_at_enrollment`

## Modeling

**Data Preparation / Preprocessing**
"""

from sklearn.preprocessing import  OneHotEncoder

# One-hot encoding untuk fitur kategorikal
data_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=False)

#Mengubah nilai True dan False menjadi 1 dan 0
data_encoded = data_encoded.astype(int)
data_encoded.head()

#Memisahkan fitur dan label
X = data_encoded.drop(['Status_Dropout','Status_Enrolled','Status_Graduate'], axis=1)
X = X[['Curricular_units_2nd_sem_approved', 'Curricular_units_2nd_sem_grade', 'Curricular_units_1st_sem_approved', 'Curricular_units_1st_sem_grade', 'Tuition_fees_up_to_date', 'Scholarship_holder', 'Curricular_units_2nd_sem_enrolled', 'Curricular_units_1st_sem_enrolled', 'Admission_grade', 'Displaced']]
y = data_encoded[['Status_Dropout','Status_Enrolled','Status_Graduate']]

"""Pemisahan Fitur (X) dan target (y), kolom fitur yang digunakan hanya 10 kolom yang memiliki korelasi tertinggi dengan kolom target."""

# Membagi data menjadi training dan testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler, LabelEncoder
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Simpan scaler agar dapat digunakan pada streamlit
joblib.dump(scaler, 'scaler.pkl')

print(X.columns)         # Menampilkan nama kolom (fitur)
print(X.shape)           # Menampilkan jumlah baris dan kolom
X.head()                 # Melihat beberapa data pertama

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

# Memeriksa bentuk data latih dan data uji
print("Data latih (X_train):", X_train.shape)
print("Data uji (X_test):", X_test.shape)
print("Target latih (y_train):", y_train.shape)
print("Target uji (y_test):", y_test.shape)

# Melihat distribusi target pada data latih dan data uji
print("Distribusi target pada data latih:")
print(y_train.value_counts(normalize=True))

print("\nDistribusi target pada data uji:")
print(y_test.value_counts(normalize=True))

"""**Model RandomForestClassifier**

Menggunakan gridsearchCV untuk mencari kombinasi hyperparameter terbaik.
"""

# Definisikan parameter grid
param_grid = {
    'n_estimators': [200, 500],
    'max_features': ['sqrt', 'log2'],
    'max_depth' : [15 ,20],
    'criterion' :['gini', 'entropy']
}

# Inisialisasi model dasar
rdf_model = RandomForestClassifier(random_state=123)

# Grid search
CV_rdf = GridSearchCV(estimator=rdf_model, param_grid=param_grid,
                           cv=5, n_jobs=-1, verbose=1, scoring='accuracy')

# Fit ke data latih
CV_rdf.fit(X_train_scaled, y_train)

# Cetak parameter terbaik
print("Best parameters:", CV_rdf.best_params_)

"""Training model menggunakan best parameter kemudian menyimpannya dalam folder model."""

# Membuat model Random Forest Classifier dengan parameter terbaik
rdf_model = RandomForestClassifier(
    random_state=123,
    max_depth=15,
    n_estimators=200,
    max_features='sqrt',
    criterion='gini',
    n_jobs=-1
)
rdf_model.fit(X_train_scaled, y_train)

# Menyimpan model
joblib.dump(rdf_model, "rdf_model.joblib")

"""## Evaluation

Evaluasi model terhadap data test dan mencetak hasilnya
"""

# Memprediksi pada data test
y_pred = rdf_model.predict(X_test_scaled)

# Evaluasi model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Classification Report:\n", report)

"""Model klasifikasi yang dibangun memiliki akurasi keseluruhan sebesar 70.96%, yang secara umum menunjukkan performa cukup baik namun perlu di tingkatkan lagi agar lebih baik."""

importances = rdf_model.feature_importances_
indices = importances.argsort()[::-1]
features = X.columns

plt.figure(figsize=(10, 8))
plt.title("Feature Importance")
plt.barh(range(len(indices)), importances[indices], align="center")
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.gca().invert_yaxis()
plt.show()

"""Fitur-fitur akademik seperti kelulusan dan nilai di semester awal sangat dominan, menunjukkan bahwa kinerja akademik di semester awal sangat menentukan apakah mahasiswa akan dropout atau tidak.

Fitur non-akademik juga muncul, meskipun dengan pengaruh yang lebih kecil, seperti Tuition_fees_up_to_date dan Displaced

## Kirim dataframe ke supabase agar dapat digunakan oleh metabase
"""

from sqlalchemy import create_engine

URL = "postgresql://postgres.kqolmoqbfhdxhagbikkc:[Your-Password]@aws-0-ap-southeast-1.pooler.supabase.com:6543/postgres"

engine = create_engine(URL)
df.to_sql('institute_dataset', engine)